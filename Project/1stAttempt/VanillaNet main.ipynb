{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS D:\\MS Purdue\\1\\ECE570> python --version\n",
    "\n",
    "Python 3.9.0\n",
    "\n",
    "PS D:\\MS Purdue\\1\\ECE570> py -3.11 --version\n",
    "\n",
    "Python 3.11.9\n",
    "\n",
    "py -3.11 -m pip list\n",
    "\n",
    "py -3.11 -m pip install <package_name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: e:\\ECE570(E)\\Project\\1stAttempt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n01440764': 0, 'n01496331': 1, 'n01530575': 2, 'n01558993': 3, 'n01601694': 4, 'n01629819': 5, 'n01641577': 6, 'n01667114': 7, 'n01682714': 8, 'n01692333': 9, 'n01698640': 10, 'n01729977': 11, 'n01740131': 12, 'n01751748': 13, 'n01770081': 14, 'n01774384': 15, 'n01795545': 16, 'n01806567': 17, 'n01820546': 18, 'n01843065': 19, 'n01860187': 20, 'n01882714': 21, 'n01924916': 22, 'n01950731': 23, 'n01980166': 24, 'n01986214': 25, 'n02007558': 26, 'n02013706': 27, 'n02027492': 28, 'n02056570': 29, 'n02077923': 30, 'n02086240': 31, 'n02088094': 32, 'n02089078': 33, 'n02090721': 34, 'n02091635': 35, 'n02093428': 36, 'n02094114': 37, 'n02095889': 38, 'n02096585': 39, 'n02097474': 40, 'n02099267': 41, 'n02100236': 42, 'n02101388': 43, 'n02102480': 44, 'n02105162': 45, 'n02105855': 46, 'n02106662': 47, 'n02107908': 48, 'n02108915': 49, 'n02110185': 50, 'n02111129': 51, 'n02112137': 52, 'n02113624': 53, 'n02114548': 54, 'n02116738': 55, 'n02120505': 56, 'n02124075': 57, 'n02128925': 58, 'n02133161': 59, 'n02165105': 60, 'n02172182': 61, 'n02219486': 62, 'n02236044': 63, 'n02268853': 64, 'n02281406': 65, 'n02325366': 66, 'n02356798': 67, 'n02391049': 68, 'n02403003': 69, 'n02417914': 70, 'n02437616': 71, 'n02444819': 72, 'n02480495': 73, 'n02484975': 74, 'n02488702': 75, 'n02493509': 76, 'n02504013': 77, 'n02526121': 78, 'n02641379': 79, 'n02669723': 80, 'n02692877': 81, 'n02727426': 82, 'n02776631': 83, 'n02787622': 84, 'n02793495': 85, 'n02802426': 86, 'n02808440': 87, 'n02823428': 88, 'n02837789': 89, 'n02860847': 90, 'n02877765': 91, 'n02894605': 92, 'n02916936': 93, 'n02948072': 94, 'n02965783': 95, 'n02977058': 96, 'n02988304': 97, 'n03000247': 98, 'n03018349': 99, 'n03042490': 100, 'n03063689': 101, 'n03095699': 102, 'n03124170': 103, 'n03131574': 104, 'n03160309': 105, 'n03196217': 106, 'n03208938': 107, 'n03240683': 108, 'n03271574': 109, 'n03297495': 110, 'n03345487': 111, 'n03379051': 112, 'n03393912': 113, 'n03424325': 114, 'n03445924': 115, 'n03457902': 116, 'n03476991': 117, 'n03485407': 118, 'n03496892': 119, 'n03532672': 120, 'n03584254': 121, 'n03595614': 122, 'n03623198': 123, 'n03642806': 124, 'n03662601': 125, 'n03680355': 126, 'n03706229': 127, 'n03717622': 128, 'n03733131': 129, 'n03759954': 130, 'n03770439': 131, 'n03776460': 132, 'n03785016': 133, 'n03791053': 134, 'n03796401': 135, 'n03825788': 136, 'n03841143': 137, 'n03868242': 138, 'n03874599': 139, 'n03887697': 140, 'n03895866': 141, 'n03908714': 142, 'n03929855': 143, 'n03937543': 144, 'n03950228': 145, 'n03967562': 146, 'n03980874': 147, 'n03995372': 148, 'n04009552': 149, 'n04033995': 150, 'n04044716': 151, 'n04070727': 152, 'n04099969': 153, 'n04120489': 154, 'n04136333': 155, 'n04147183': 156, 'n04162706': 157, 'n04204238': 158, 'n04228054': 159, 'n04243546': 160, 'n04254680': 161, 'n04264628': 162, 'n04275548': 163, 'n04310018': 164, 'n04326547': 165, 'n04336792': 166, 'n04355338': 167, 'n04367480': 168, 'n04376876': 169, 'n04399382': 170, 'n04423845': 171, 'n04443257': 172, 'n04462240': 173, 'n04482393': 174, 'n04487394': 175, 'n04509417': 176, 'n04525038': 177, 'n04540053': 178, 'n04552348': 179, 'n04562935': 180, 'n04590129': 181, 'n04597913': 182, 'n04613696': 183, 'n06874185': 184, 'n07584110': 185, 'n07684084': 186, 'n07711569': 187, 'n07716906': 188, 'n07720875': 189, 'n07747607': 190, 'n07754684': 191, 'n07836838': 192, 'n07880968': 193, 'n09193705': 194, 'n09332890': 195, 'n09472597': 196, 'n11939491': 197, 'n12768682': 198, 'n13044778': 199}\n",
      "{'n01440764': 0, 'n01496331': 1, 'n01530575': 2, 'n01558993': 3, 'n01601694': 4, 'n01629819': 5, 'n01641577': 6, 'n01667114': 7, 'n01682714': 8, 'n01692333': 9, 'n01698640': 10, 'n01729977': 11, 'n01740131': 12, 'n01751748': 13, 'n01770081': 14, 'n01774384': 15, 'n01795545': 16, 'n01806567': 17, 'n01820546': 18, 'n01843065': 19, 'n01860187': 20, 'n01882714': 21, 'n01924916': 22, 'n01950731': 23, 'n01980166': 24, 'n01986214': 25, 'n02007558': 26, 'n02013706': 27, 'n02027492': 28, 'n02056570': 29, 'n02077923': 30, 'n02086240': 31, 'n02088094': 32, 'n02089078': 33, 'n02090721': 34, 'n02091635': 35, 'n02093428': 36, 'n02094114': 37, 'n02095889': 38, 'n02096585': 39, 'n02097474': 40, 'n02099267': 41, 'n02100236': 42, 'n02101388': 43, 'n02102480': 44, 'n02105162': 45, 'n02105855': 46, 'n02106662': 47, 'n02107908': 48, 'n02108915': 49, 'n02110185': 50, 'n02111129': 51, 'n02112137': 52, 'n02113624': 53, 'n02114548': 54, 'n02116738': 55, 'n02120505': 56, 'n02124075': 57, 'n02128925': 58, 'n02133161': 59, 'n02165105': 60, 'n02172182': 61, 'n02219486': 62, 'n02236044': 63, 'n02268853': 64, 'n02281406': 65, 'n02325366': 66, 'n02356798': 67, 'n02391049': 68, 'n02403003': 69, 'n02417914': 70, 'n02437616': 71, 'n02444819': 72, 'n02480495': 73, 'n02484975': 74, 'n02488702': 75, 'n02493509': 76, 'n02504013': 77, 'n02526121': 78, 'n02641379': 79, 'n02669723': 80, 'n02692877': 81, 'n02727426': 82, 'n02776631': 83, 'n02787622': 84, 'n02793495': 85, 'n02802426': 86, 'n02808440': 87, 'n02823428': 88, 'n02837789': 89, 'n02860847': 90, 'n02877765': 91, 'n02894605': 92, 'n02916936': 93, 'n02948072': 94, 'n02965783': 95, 'n02977058': 96, 'n02988304': 97, 'n03000247': 98, 'n03018349': 99, 'n03042490': 100, 'n03063689': 101, 'n03095699': 102, 'n03124170': 103, 'n03131574': 104, 'n03160309': 105, 'n03196217': 106, 'n03208938': 107, 'n03240683': 108, 'n03271574': 109, 'n03297495': 110, 'n03345487': 111, 'n03379051': 112, 'n03393912': 113, 'n03424325': 114, 'n03445924': 115, 'n03457902': 116, 'n03476991': 117, 'n03485407': 118, 'n03496892': 119, 'n03532672': 120, 'n03584254': 121, 'n03595614': 122, 'n03623198': 123, 'n03642806': 124, 'n03662601': 125, 'n03680355': 126, 'n03706229': 127, 'n03717622': 128, 'n03733131': 129, 'n03759954': 130, 'n03770439': 131, 'n03776460': 132, 'n03785016': 133, 'n03791053': 134, 'n03796401': 135, 'n03825788': 136, 'n03841143': 137, 'n03868242': 138, 'n03874599': 139, 'n03887697': 140, 'n03895866': 141, 'n03908714': 142, 'n03929855': 143, 'n03937543': 144, 'n03950228': 145, 'n03967562': 146, 'n03980874': 147, 'n03995372': 148, 'n04009552': 149, 'n04033995': 150, 'n04044716': 151, 'n04070727': 152, 'n04099969': 153, 'n04120489': 154, 'n04136333': 155, 'n04147183': 156, 'n04162706': 157, 'n04204238': 158, 'n04228054': 159, 'n04243546': 160, 'n04254680': 161, 'n04264628': 162, 'n04275548': 163, 'n04310018': 164, 'n04326547': 165, 'n04336792': 166, 'n04355338': 167, 'n04367480': 168, 'n04376876': 169, 'n04399382': 170, 'n04423845': 171, 'n04443257': 172, 'n04462240': 173, 'n04482393': 174, 'n04487394': 175, 'n04509417': 176, 'n04525038': 177, 'n04540053': 178, 'n04552348': 179, 'n04562935': 180, 'n04590129': 181, 'n04597913': 182, 'n04613696': 183, 'n06874185': 184, 'n07584110': 185, 'n07684084': 186, 'n07711569': 187, 'n07716906': 188, 'n07720875': 189, 'n07747607': 190, 'n07754684': 191, 'n07836838': 192, 'n07880968': 193, 'n09193705': 194, 'n09332890': 195, 'n09472597': 196, 'n11939491': 197, 'n12768682': 198, 'n13044778': 199}\n",
      "Train subset size: 100000\n",
      "Validation subset size: 10000\n",
      "torch.Size([8, 3, 256, 256]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # Resize to Tiny ImageNet's image size\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),\n",
    "    # Normalization\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalization\n",
    "])\n",
    "\n",
    "# Path to dataset\n",
    "data_dir = '../cleaned_dataset/'\n",
    "\n",
    "# Load training and validation data\n",
    "train_dataset = datasets.ImageFolder(root=data_dir + 'train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=data_dir + 'val', transform=transform)\n",
    "\n",
    "\n",
    "# DataLoader for batching\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check class-to-index mapping\n",
    "print(train_dataset.class_to_idx) # Class labels\n",
    "# Check class-to-index mapping and dataset size\n",
    "print(train_dataset.class_to_idx)  # Class labels\n",
    "\n",
    "print(f\"Train subset size: {len(train_dataset)}\")\n",
    "print(f\"Validation subset size: {len(val_dataset)}\")\n",
    "\n",
    "# Example: Iterate through the train_loader to test\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 10.00 GiB already allocated; 0 bytes free; 10.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvanillanet_NN\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vanillanet_5, vanillanet_6, vanillanet_9\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create an instance of the VanillaNet model (VanillaNet-9 in this case)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvanillanet_9\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Print model architecture to verify\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 570 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 593\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 10.00 GiB already allocated; 0 bytes free; 10.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "# Import the specific functions from the vanillanet.py file\n",
    "from vanillanet_NN import vanillanet_5, vanillanet_6, vanillanet_9\n",
    "\n",
    "# Create an instance of the VanillaNet model (VanillaNet-9 in this case)\n",
    "model = vanillanet_9(pretrained=False, num_classes=200).to(device)  \n",
    "\n",
    "# Print model architecture to verify\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 4.00 GiB total capacity; 9.74 GiB already allocated; 0 bytes free; 9.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\ECE570(E)\\Project\\1stAttempt\\vanillanet_NN.py:192\u001b[0m, in \u001b[0;36mVanillaNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    190\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem1(x)\n\u001b[0;32m    191\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(x,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_learn)\n\u001b[1;32m--> 192\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m    195\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages[i](x)\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\ECE570(E)\\Project\\1stAttempt\\vanillanet_NN.py:35\u001b[0m, in \u001b[0;36mactivation.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28msuper\u001b[39m(activation, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mforward(x), \n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_num, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_num, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim))\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\activation.py:98\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alanc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:1299\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1299\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 4.00 GiB total capacity; 9.74 GiB already allocated; 0 bytes free; 9.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt  \n",
    "from timm.optim import AdamP  \n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = AdamP(model.parameters(), lr=0.001, weight_decay=0.35)  # LAMB or AdamP with weight decay\n",
    "\n",
    "# Early Stopping Parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 10000  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # No need to calculate gradients during validation\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss and accuracy\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.2f}%, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "\n",
    "    if(epoch % 10 == 0):\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_accuracy': val_accuracy,\n",
    "        }\n",
    "        torch.save(checkpoint, f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        # Save the best model\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_val_loss,\n",
    "        }, 'best_checkpoint.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "print('Training complete!')\n",
    "\n",
    "# Plotting only up to the epoch where training stopped\n",
    "epochs = range(1, epoch + 2)  # Adjust the range to match the actual number of trained epochs\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, 'bo-', label='Train Loss')\n",
    "plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, 'bo-', label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'ro-', label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot after training completion\n",
    "plt.savefig('training_progress.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
